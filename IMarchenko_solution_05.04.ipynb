{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 12) (10000, 11)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('d:\\\\GB course\\\\alg2\\\\train.csv')\n",
    "test = pd.read_csv('d:\\\\GB course\\\\alg2\\\\test.csv')\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      "Id                     10000 non-null int64\n",
      "age                    10000 non-null float64\n",
      "years_of_experience    10000 non-null float64\n",
      "lesson_price           10000 non-null float64\n",
      "qualification          10000 non-null float64\n",
      "physics                10000 non-null float64\n",
      "chemistry              10000 non-null float64\n",
      "biology                10000 non-null float64\n",
      "english                10000 non-null float64\n",
      "geography              10000 non-null float64\n",
      "history                10000 non-null float64\n",
      "mean_exam_points       10000 non-null float64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 937.6 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>lesson_price</th>\n",
       "      <th>qualification</th>\n",
       "      <th>physics</th>\n",
       "      <th>chemistry</th>\n",
       "      <th>biology</th>\n",
       "      <th>english</th>\n",
       "      <th>geography</th>\n",
       "      <th>history</th>\n",
       "      <th>mean_exam_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4999.50000</td>\n",
       "      <td>45.878000</td>\n",
       "      <td>1.986800</td>\n",
       "      <td>1699.105000</td>\n",
       "      <td>1.719500</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.132900</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>64.340800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>8.043929</td>\n",
       "      <td>1.772213</td>\n",
       "      <td>524.886654</td>\n",
       "      <td>0.792264</td>\n",
       "      <td>0.484147</td>\n",
       "      <td>0.339484</td>\n",
       "      <td>0.312406</td>\n",
       "      <td>0.225436</td>\n",
       "      <td>0.176274</td>\n",
       "      <td>0.137933</td>\n",
       "      <td>13.536823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2499.75000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4999.50000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7499.25000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2150.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9999.00000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3950.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id           age  years_of_experience  lesson_price  \\\n",
       "count  10000.00000  10000.000000         10000.000000  10000.000000   \n",
       "mean    4999.50000     45.878000             1.986800   1699.105000   \n",
       "std     2886.89568      8.043929             1.772213    524.886654   \n",
       "min        0.00000     23.000000             0.000000    200.000000   \n",
       "25%     2499.75000     40.000000             0.000000   1300.000000   \n",
       "50%     4999.50000     46.000000             2.000000   1500.000000   \n",
       "75%     7499.25000     51.000000             3.000000   2150.000000   \n",
       "max     9999.00000     68.000000            10.000000   3950.000000   \n",
       "\n",
       "       qualification       physics     chemistry       biology       english  \\\n",
       "count   10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean        1.719500      0.375000      0.132900      0.109600      0.053700   \n",
       "std         0.792264      0.484147      0.339484      0.312406      0.225436   \n",
       "min         1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         2.000000      1.000000      0.000000      0.000000      0.000000   \n",
       "max         4.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          geography       history  mean_exam_points  \n",
       "count  10000.000000  10000.000000      10000.000000  \n",
       "mean       0.032100      0.019400         64.340800  \n",
       "std        0.176274      0.137933         13.536823  \n",
       "min        0.000000      0.000000         32.000000  \n",
       "25%        0.000000      0.000000         55.000000  \n",
       "50%        0.000000      0.000000         63.000000  \n",
       "75%        0.000000      0.000000         73.000000  \n",
       "max        1.000000      1.000000        100.000000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>age</th>\n",
       "      <th>years_of_experience</th>\n",
       "      <th>lesson_price</th>\n",
       "      <th>qualification</th>\n",
       "      <th>physics</th>\n",
       "      <th>chemistry</th>\n",
       "      <th>biology</th>\n",
       "      <th>english</th>\n",
       "      <th>geography</th>\n",
       "      <th>history</th>\n",
       "      <th>mean_exam_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004596</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>-0.004433</td>\n",
       "      <td>-0.005077</td>\n",
       "      <td>-0.010570</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>-0.014869</td>\n",
       "      <td>-0.004482</td>\n",
       "      <td>0.004121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.004596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059947</td>\n",
       "      <td>-0.005462</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>-0.005026</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>0.013130</td>\n",
       "      <td>0.010606</td>\n",
       "      <td>-0.007646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years_of_experience</th>\n",
       "      <td>0.007408</td>\n",
       "      <td>0.059947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.248311</td>\n",
       "      <td>0.194097</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>-0.010241</td>\n",
       "      <td>-0.011129</td>\n",
       "      <td>0.018640</td>\n",
       "      <td>0.205417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lesson_price</th>\n",
       "      <td>-0.004433</td>\n",
       "      <td>-0.005462</td>\n",
       "      <td>0.248311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.790087</td>\n",
       "      <td>-0.006432</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>-0.004860</td>\n",
       "      <td>-0.012018</td>\n",
       "      <td>0.010525</td>\n",
       "      <td>-0.001142</td>\n",
       "      <td>0.721179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualification</th>\n",
       "      <td>-0.005077</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>0.194097</td>\n",
       "      <td>0.790087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007529</td>\n",
       "      <td>-0.002683</td>\n",
       "      <td>-0.007504</td>\n",
       "      <td>-0.008047</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>0.755963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physics</th>\n",
       "      <td>-0.010570</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.008451</td>\n",
       "      <td>-0.006432</td>\n",
       "      <td>0.007529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019852</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>0.187726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chemistry</th>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>-0.002683</td>\n",
       "      <td>0.019852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007866</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>-0.004447</td>\n",
       "      <td>-0.008079</td>\n",
       "      <td>0.017825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biology</th>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.005026</td>\n",
       "      <td>-0.001722</td>\n",
       "      <td>-0.004860</td>\n",
       "      <td>-0.007504</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.007866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010146</td>\n",
       "      <td>-0.013042</td>\n",
       "      <td>0.010995</td>\n",
       "      <td>0.023022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>english</th>\n",
       "      <td>0.017723</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.010241</td>\n",
       "      <td>-0.012018</td>\n",
       "      <td>-0.008047</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>0.010146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008148</td>\n",
       "      <td>-0.004560</td>\n",
       "      <td>0.013174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geography</th>\n",
       "      <td>-0.014869</td>\n",
       "      <td>0.013130</td>\n",
       "      <td>-0.011129</td>\n",
       "      <td>0.010525</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>-0.004447</td>\n",
       "      <td>-0.013042</td>\n",
       "      <td>-0.008148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005049</td>\n",
       "      <td>0.014401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>history</th>\n",
       "      <td>-0.004482</td>\n",
       "      <td>0.010606</td>\n",
       "      <td>0.018640</td>\n",
       "      <td>-0.001142</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>-0.008079</td>\n",
       "      <td>0.010995</td>\n",
       "      <td>-0.004560</td>\n",
       "      <td>-0.005049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_exam_points</th>\n",
       "      <td>0.004121</td>\n",
       "      <td>-0.007646</td>\n",
       "      <td>0.205417</td>\n",
       "      <td>0.721179</td>\n",
       "      <td>0.755963</td>\n",
       "      <td>0.187726</td>\n",
       "      <td>0.017825</td>\n",
       "      <td>0.023022</td>\n",
       "      <td>0.013174</td>\n",
       "      <td>0.014401</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Id       age  years_of_experience  lesson_price  \\\n",
       "Id                   1.000000 -0.004596             0.007408     -0.004433   \n",
       "age                 -0.004596  1.000000             0.059947     -0.005462   \n",
       "years_of_experience  0.007408  0.059947             1.000000      0.248311   \n",
       "lesson_price        -0.004433 -0.005462             0.248311      1.000000   \n",
       "qualification       -0.005077 -0.000976             0.194097      0.790087   \n",
       "physics             -0.010570  0.004045             0.008451     -0.006432   \n",
       "chemistry            0.002694  0.001250             0.004246      0.005130   \n",
       "biology             -0.000016 -0.005026            -0.001722     -0.004860   \n",
       "english              0.017723 -0.012546            -0.010241     -0.012018   \n",
       "geography           -0.014869  0.013130            -0.011129      0.010525   \n",
       "history             -0.004482  0.010606             0.018640     -0.001142   \n",
       "mean_exam_points     0.004121 -0.007646             0.205417      0.721179   \n",
       "\n",
       "                     qualification   physics  chemistry   biology   english  \\\n",
       "Id                       -0.005077 -0.010570   0.002694 -0.000016  0.017723   \n",
       "age                      -0.000976  0.004045   0.001250 -0.005026 -0.012546   \n",
       "years_of_experience       0.194097  0.008451   0.004246 -0.001722 -0.010241   \n",
       "lesson_price              0.790087 -0.006432   0.005130 -0.004860 -0.012018   \n",
       "qualification             1.000000  0.007529  -0.002683 -0.007504 -0.008047   \n",
       "physics                   0.007529  1.000000   0.019852  0.000661  0.004238   \n",
       "chemistry                -0.002683  0.019852   1.000000  0.007866  0.009974   \n",
       "biology                  -0.007504  0.000661   0.007866  1.000000  0.010146   \n",
       "english                  -0.008047  0.004238   0.009974  0.010146  1.000000   \n",
       "geography                 0.003610  0.001904  -0.004447 -0.013042 -0.008148   \n",
       "history                  -0.005109  0.004867  -0.008079  0.010995 -0.004560   \n",
       "mean_exam_points          0.755963  0.187726   0.017825  0.023022  0.013174   \n",
       "\n",
       "                     geography   history  mean_exam_points  \n",
       "Id                   -0.014869 -0.004482          0.004121  \n",
       "age                   0.013130  0.010606         -0.007646  \n",
       "years_of_experience  -0.011129  0.018640          0.205417  \n",
       "lesson_price          0.010525 -0.001142          0.721179  \n",
       "qualification         0.003610 -0.005109          0.755963  \n",
       "physics               0.001904  0.004867          0.187726  \n",
       "chemistry            -0.004447 -0.008079          0.017825  \n",
       "biology              -0.013042  0.010995          0.023022  \n",
       "english              -0.008148 -0.004560          0.013174  \n",
       "geography             1.000000 -0.005049          0.014401  \n",
       "history              -0.005049  1.000000         -0.000113  \n",
       "mean_exam_points      0.014401 -0.000113          1.000000  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_NAME = 'mean_exam_points'\n",
    "FEATURE_NAMES = ['age', 'years_of_experience', 'lesson_price', 'qualification',\n",
    "       'physics', 'chemistry', 'biology', 'english', 'geography', 'history']\n",
    "\n",
    "# не забыть, для дерева лучше вариант + 1 и 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10) (10000,)\n"
     ]
    }
   ],
   "source": [
    "X = train[FEATURE_NAMES].values\n",
    "y = train[TARGET_NAME].values\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(X, y, \n",
    "                                                                    test_size = 0.3,\n",
    "                                                                    random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# общие функции\n",
    "def r_2(y_pred, y_true):\n",
    "    numerator = ((y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)\n",
    "    denominator = ((y_true - np.average(y_true)) ** 2).sum(axis=0, dtype=np.float64)\n",
    "    return 1 - (numerator / denominator)\n",
    "\n",
    "def mean_squared_error(y_real, prediction):\n",
    "    return (sum((y_real - prediction)**2)) / len(y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index  # индекс признака, по которому ведется сравнение с порогом в этом узле\n",
    "        self.t = t  # значение порога\n",
    "        self.true_branch = true_branch  # поддерево, удовлетворяющее условию в узле\n",
    "        self.false_branch = false_branch  # поддерево, не удовлетворяющее условию в узле\n",
    "        \n",
    "# И класс терминального узла (листа)\n",
    "class Leaf:\n",
    "    \n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction_classification = self.predict()\n",
    "        self.prediction_regression = self.predict_reg()\n",
    "        \n",
    "    def predict(self):\n",
    "        # подсчет количества объектов разных классов\n",
    "        classes = {}  # сформируем словарь \"класс: количество объектов\"\n",
    "        for label in self.labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "        #  найдем класс, количество объектов которого будет максимальным в этом листе и вернем его    \n",
    "        prediction = max(classes, key=classes.get)\n",
    "        return prediction  \n",
    "\n",
    "    def predict_reg(self):\n",
    "        #  найдем значение как среднее по выборке   \n",
    "        prediction = np.mean(self.labels)\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расчёт дисперсии значений (вместо gini)\n",
    "def dispersion(labels):\n",
    "    return np.std(labels)\n",
    "\n",
    "\n",
    "# Расчет качества для задачи регрессии\n",
    "def quality_regression(left_labels, right_labels, current_dispersion):\n",
    "\n",
    "    # доля выбоки, ушедшая в левое поддерево\n",
    "    p = float(left_labels.shape[0]) / (left_labels.shape[0] + right_labels.shape[0])\n",
    "    return current_dispersion - p * dispersion(left_labels) - (1 - p) * dispersion(right_labels)\n",
    "\n",
    "\n",
    "# аналог classify_object для регрессии\n",
    "def predict_object(obj, node):\n",
    "\n",
    "    #  Останавливаем рекурсию, если достигли листа\n",
    "    if isinstance(node, Leaf):\n",
    "        answer = node.prediction_regression\n",
    "        return answer\n",
    "\n",
    "    if obj[node.index] <= node.t:\n",
    "        return predict_object(obj, node.true_branch)\n",
    "    else:\n",
    "        return predict_object(obj, node.false_branch)\n",
    "\n",
    "    \n",
    "# аналог predict_class для регрессии\n",
    "def predict_value(data, tree):\n",
    "    val = []\n",
    "    for obj in data:\n",
    "        prediction = predict_object(obj, tree)\n",
    "        val.append(prediction)\n",
    "    return val\n",
    "    \n",
    "# Разбиение датасета в узле\n",
    "def split(data, labels, index, t):\n",
    "    \n",
    "    left = np.where(data[:, index] <= t)\n",
    "    right = np.where(data[:, index] > t)\n",
    "        \n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "        \n",
    "    return true_data, false_data, true_labels, false_labels\n",
    "\n",
    "# Нахождение наилучшего разбиения для задачи регрессии\n",
    "def find_best_split_regression(data, labels):\n",
    "    \n",
    "    #  обозначим минимальное количество объектов в узле\n",
    "    min_leaf = 5\n",
    "\n",
    "    current_dispersion = dispersion(labels)\n",
    "\n",
    "    best_quality = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    for index in range(n_features):\n",
    "        # будем проверять только уникальные значения признака, исключая повторения\n",
    "        t_values = np.unique([row[index] for row in data])\n",
    "        \n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "            if len(true_data) < min_leaf or len(false_data) < min_leaf:\n",
    "                continue\n",
    "            \n",
    "            current_quality = quality_regression(true_labels, false_labels, current_dispersion)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_quality > best_quality:\n",
    "                best_quality, best_t, best_index = current_quality, t, index\n",
    "\n",
    "    return best_quality, best_t, best_index\n",
    "\n",
    "\n",
    "# Построение дерева регрессии с помощью рекурсивной функции\n",
    "def build_tree_regression(data, labels, tree_depth=0, max_depth=50):\n",
    "\n",
    "    quality, t, index = find_best_split_regression(data, labels)\n",
    "\n",
    "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "    if quality == 0:\n",
    "        return Leaf(data, labels)\n",
    "\n",
    "    # Базовый случай (2) - прекращаем рекурсию, когда достигнута максимальная глубина дерева\n",
    "    if tree_depth >= max_depth:\n",
    "        return Leaf(data, labels)\n",
    "\n",
    "    # Увеличиваем глубину дерева на 1\n",
    "    tree_depth += 1\n",
    "\n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "\n",
    "    # Рекурсивно строим два поддерева\n",
    "    true_branch = build_tree_regression(true_data, true_labels, tree_depth, max_depth)\n",
    "    false_branch = build_tree_regression(false_data, false_labels, tree_depth, max_depth)\n",
    "\n",
    "    \n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return Node(index, t, true_branch, false_branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "def get_bootstrap(data, labels, N):\n",
    "       \n",
    "    n_samples = data.shape[0]\n",
    "    bootstrap = []\n",
    "\n",
    "    for i in range(N):\n",
    "        b_data = np.zeros(data.shape)\n",
    "        b_labels = np.zeros(labels.shape)\n",
    "\n",
    "        for j in range(n_samples):\n",
    "            sample_index = np.random.randint(0, n_samples-1)\n",
    "            b_data[j] = data[sample_index]\n",
    "            b_labels[j] = labels[sample_index]\n",
    "        bootstrap.append((b_data, b_labels))\n",
    "\n",
    "    return bootstrap\n",
    "\n",
    "def get_subsample(len_sample):\n",
    "    \n",
    "    sample_indexes = [i for i in range(len_sample)]\n",
    "    \n",
    "    len_subsample = int(np.sqrt(len_sample))\n",
    "    subsample = []\n",
    "    \n",
    "    np.random.shuffle(sample_indexes)\n",
    "    for i in range(len_subsample):\n",
    "        subsample.append(sample_indexes.pop())\n",
    "        \n",
    "    return subsample\n",
    "\n",
    "def find_best_split_forest(data, labels, min_leaf=1):\n",
    "\n",
    "    current_dispersion = dispersion(labels)\n",
    "\n",
    "    best_quality = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    \n",
    "    n_features = data.shape[1]\n",
    "    \n",
    "    # выбор индекса из подвыборки длиной sqrt(n_features)\n",
    "    subsample = get_subsample(n_features)\n",
    "    \n",
    "    for index in subsample:\n",
    "        t_values = [row[index] for row in data]\n",
    "        \n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "            #  пропускаем разбиения, в которых в узле остается менее 5 объектов\n",
    "            if len(true_data) < min_leaf or len(false_data) < min_leaf:\n",
    "                continue\n",
    "            \n",
    "            current_quality = quality_regression(true_labels, false_labels, current_dispersion)\n",
    "            \n",
    "            #  выбираем порог, на котором получается максимальный прирост качества\n",
    "            if current_quality > best_quality:\n",
    "                best_quality, best_t, best_index = current_quality, t, index\n",
    "\n",
    "    return best_quality, best_t, best_index\n",
    "\n",
    "# Построение дерева с помощью рекурсивной функции\n",
    "\n",
    "def build_tree_forest(data, labels):\n",
    "\n",
    "    quality, t, index = find_best_split_forest(data, labels, min_leaf=1)\n",
    "\n",
    "    #  Базовый случай - прекращаем рекурсию, когда нет прироста в качества\n",
    "    if quality == 0:\n",
    "        return Leaf(data, labels)\n",
    "\n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "\n",
    "    # Рекурсивно строим два поддерева\n",
    "    true_branch = build_tree_forest(true_data, true_labels)\n",
    "    false_branch = build_tree_forest(false_data, false_labels)\n",
    "\n",
    "    # Возвращаем класс узла со всеми поддеревьями, то есть целого дерева\n",
    "    return Node(index, t, true_branch, false_branch)\n",
    "\n",
    "def random_forest(data, labels, n_trees):\n",
    "    \n",
    "    forest = []\n",
    "    bootstrap = get_bootstrap(data, labels, n_trees)\n",
    "    \n",
    "    for b_data, b_labels in bootstrap:\n",
    "        forest.append(build_tree_forest(b_data, b_labels))\n",
    "        \n",
    "    return forest\n",
    "\n",
    "def tree_vote(forest, data):\n",
    "    \n",
    "    predictions = []\n",
    "    for tree in forest:\n",
    "        predictions.append(predict_value(data, tree))\n",
    "        \n",
    "    predictions_per_object = list(zip(*predictions))\n",
    "    \n",
    "    voted_predictions = []\n",
    "    for obj in predictions_per_object:\n",
    "        voted_predictions.append(np.mean(obj))\n",
    "    \n",
    "    return voted_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv(y, z):\n",
    "    return (y - z)\n",
    "\n",
    "\n",
    "def gb_predict(X, trees_list, coef_list, eta):\n",
    "#     return np.array([sum([eta*coef*alg.predict([x])[0] for alg, coef in zip(trees_list,coef_list)]) for x in X])\n",
    "#     print(predict_value([X[0]],trees_list[0])[0])\n",
    "#     return np.array([sum([eta*coef*predict_value([x],alg)[0] for alg, coef in zip(trees_list,coef_list)]) for x in X])\n",
    "    return np.array([sum([eta*coef*predict_value([x],alg)[0] for alg, coef in zip(trees_list,coef_list)]) for x in X])\n",
    "\n",
    "\n",
    "\n",
    "def gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta):\n",
    "    \n",
    "    # Деревья будем записывать в список\n",
    "    trees = []\n",
    "    \n",
    "    # Будем записывать ошибки на обучающей и тестовой выборке на каждой итерации в список\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    \n",
    "    for i in range(n_trees):\n",
    "        # инициализируем бустинг начальным алгоритмом, возвращающим ноль, \n",
    "        # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
    "        if len(trees) == 0:\n",
    "            tree = build_tree_regression(X_train, y_train, 0, max_depth)\n",
    "            \n",
    "            train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
    "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
    "        else:\n",
    "            # Получим ответы на текущей композиции\n",
    "            pred = gb_predict(X_train, trees, coefs, eta)\n",
    "            \n",
    "            # алгоритмы начиная со второго обучаем на сдвиг\n",
    "            tree = build_tree_regression(X_train, deriv(y_train, pred), 0, max_depth)\n",
    "            \n",
    "            train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
    "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
    "            \n",
    "        trees.append(tree)\n",
    "        \n",
    "    return trees, train_errors, test_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### одно дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8477989158827512, 0.718809791743815)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tree_regression = build_tree_regression(train_data, train_labels)\n",
    "\n",
    "# Получим ответы для обучающей выборки \n",
    "train_answers = predict_value(train_data, my_tree_regression)\n",
    "\n",
    "# И получим ответы для тестовой выборки\n",
    "test_answers = predict_value(test_data, my_tree_regression)\n",
    "\n",
    "r_2(train_answers, train_labels), r_2(test_answers, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВЫВОД: неплохо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8297725443001466, 0.7341501928780205)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "n_trees = 3\n",
    "my_forest = random_forest(train_data, train_labels, n_trees)\n",
    "\n",
    "train_answs = tree_vote(my_forest, train_data)\n",
    "test_answs = tree_vote(my_forest, test_data)\n",
    "\n",
    "r_2(train_answs, train_labels), r_2(test_answs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8467985512731653, 0.7448483290641434)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "n_trees = 5\n",
    "my_forest = random_forest(train_data, train_labels, n_trees)\n",
    "\n",
    "train_answs = tree_vote(my_forest, train_data)\n",
    "test_answs = tree_vote(my_forest, test_data)\n",
    "\n",
    "r_2(train_answs, train_labels), r_2(test_answs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8584223689152608, 0.7603164126888322)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "n_trees = 10\n",
    "my_forest = random_forest(train_data, train_labels, n_trees)\n",
    "\n",
    "train_answs = tree_vote(my_forest, train_data)\n",
    "test_answs = tree_vote(my_forest, test_data)\n",
    "\n",
    "r_2(train_answs, train_labels), r_2(test_answs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8594003434164015, 0.7604486934355118)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "n_trees = 15\n",
    "my_forest = random_forest(train_data, train_labels, n_trees)\n",
    "\n",
    "train_answs = tree_vote(my_forest, train_data)\n",
    "test_answs = tree_vote(my_forest, test_data)\n",
    "\n",
    "r_2(train_answs, train_labels), r_2(test_answs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8596520004054371, 0.7605522559500619)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "n_trees = 20\n",
    "my_forest = random_forest(train_data, train_labels, n_trees)\n",
    "\n",
    "train_answs = tree_vote(my_forest, train_data)\n",
    "test_answs = tree_vote(my_forest, test_data)\n",
    "\n",
    "r_2(train_answs, train_labels), r_2(test_answs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17min 5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8599089362127528, 0.7619033371537313)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "n_trees = 30\n",
    "my_forest = random_forest(train_data, train_labels, n_trees)\n",
    "\n",
    "train_answs = tree_vote(my_forest, train_data)\n",
    "test_answs = tree_vote(my_forest, test_data)\n",
    "\n",
    "r_2(train_answs, train_labels), r_2(test_answs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.86013515293706, 0.7648292276004779)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "n_trees = 50\n",
    "my_forest = random_forest(train_data, train_labels, n_trees)\n",
    "\n",
    "train_answs = tree_vote(my_forest, train_data)\n",
    "test_answs = tree_vote(my_forest, test_data)\n",
    "\n",
    "r_2(train_answs, train_labels), r_2(test_answs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8603283933552525, 0.7653699473616646)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "n_trees = 100\n",
    "my_forest = random_forest(train_data, train_labels, n_trees)\n",
    "\n",
    "train_answs = tree_vote(my_forest, train_data)\n",
    "test_answs = tree_vote(my_forest, test_data)\n",
    "\n",
    "r_2(train_answs, train_labels), r_2(test_answs, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВЫВОД - лучше чем 1 дерево. но долго строится. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = 10\n",
    "coefs = [1] * n_trees\n",
    "max_depth = 5\n",
    "eta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7947871131978343 0.7687875627627736\n",
      "Wall time: 8.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trees, train_errors, test_errors = gb_fit(n_trees, max_depth, train_data, test_data, train_labels, test_labels, coefs, eta)\n",
    "\n",
    "train_prediction = gb_predict(train_data, trees, coefs, eta)\n",
    "test_prediction = gb_predict(test_data, trees, coefs, eta)\n",
    "\n",
    "print(r_2(train_prediction, train_labels), r_2(test_prediction, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВЫВОД: даже при дефолтных параметрах лучше чем самый сложный лес на 100 деревьев. И отбрабатывает почти мгновенно. а если поискать параметры, будет вообще огонь. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Поиск параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# комменчу, чтобы не дай бог случайно не запустить, отрабатывает почти полтора часа\n",
    "# поищу параметры получше\n",
    "# лучший вариант - \n",
    "# второй сверху - \n",
    "\n",
    "# j_ = []\n",
    "# i_ = []\n",
    "# max_depth_ = []\n",
    "# r2_1 = []\n",
    "# r2_2 = []\n",
    "\n",
    "# for j in range(10,20):\n",
    "#     for i in np.linspace(0.1,1,10)::\n",
    "#         for max_depth in range(5,8):\n",
    "#             n_trees = j\n",
    "#             coefs = [1] * n_trees\n",
    "#             # max_depth = 5\n",
    "#             eta = i\n",
    "\n",
    "#             trees, train_errors, test_errors = gb_fit(n_trees, max_depth, train_data, test_data, train_labels, test_labels, coefs, eta)\n",
    "\n",
    "#             train_prediction = gb_predict(train_data, trees, coefs, eta)\n",
    "#             test_prediction = gb_predict(test_data, trees, coefs, eta)\n",
    "\n",
    "#             j_.append(j)\n",
    "#             i_.append(i)\n",
    "#             max_depth_.append(max_depth)\n",
    "#             r2_1.append(r_2(train_prediction, train_labels))\n",
    "#             r2_2.append(r_2(test_prediction, test_labels))\n",
    "            \n",
    "\n",
    "# df = pd.DataFrame(list(zip(j_, i_,max_depth_,r2_1,r2_2))).sort_values(by=4, ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучшие результаты:\n",
    "* 18\t0.3\t6\t0,803517566\t0,774918336 - на кагле 0.78331\n",
    "* 17\t0.3\t6\t0,803331613\t0,774835407 - на кагле 0.78325\n",
    "* 19\t0.3\t6\t0,803697768\t0,774830306 - на кагле 0.78330\n",
    "* 16\t0.3\t6\t0,803027701\t0,774738657 - на кагле 0.78304"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## бустинг, итоговые параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8035175660952519 0.7749183363735109\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_trees = 18\n",
    "coefs = [1] * n_trees\n",
    "max_depth = 6\n",
    "eta = 0.3\n",
    "\n",
    "trees, train_errors, test_errors = gb_fit(n_trees, max_depth, train_data, test_data, train_labels, test_labels, coefs, eta)\n",
    "\n",
    "train_prediction = gb_predict(train_data, trees, coefs, eta)\n",
    "test_prediction = gb_predict(test_data, trees, coefs, eta)\n",
    "\n",
    "print(r_2(train_prediction, train_labels), r_2(test_prediction, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      "Id                     10000 non-null int64\n",
      "age                    10000 non-null float64\n",
      "years_of_experience    10000 non-null float64\n",
      "lesson_price           10000 non-null float64\n",
      "qualification          10000 non-null float64\n",
      "physics                10000 non-null float64\n",
      "chemistry              10000 non-null float64\n",
      "biology                10000 non-null float64\n",
      "english                10000 non-null float64\n",
      "geography              10000 non-null float64\n",
      "history                10000 non-null float64\n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 859.5 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "pred_data = test[FEATURE_NAMES].values\n",
    "print(pred_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дерево - 0.77797 \n",
    "pred_labels = predict_value(pred_data, my_tree_regression)\n",
    "result = pd.concat([test['Id'], pd.Series(pred_labels)], axis=1)\n",
    "result = result.rename(columns={0: 'mean_exam_points'})\n",
    "result.to_csv('IMarchenko_predictions.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# лес - 0.77801 100 деревьев\n",
    "\n",
    "pred_labels = tree_vote(my_forest, pred_data) \n",
    "result = pd.concat([test['Id'], pd.Series(pred_labels)], axis=1)\n",
    "result = result.rename(columns={0: 'mean_exam_points'})\n",
    "result.to_csv('IMarchenko_predictions.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# бустинг - ???\n",
    "pred_labels = gb_predict(pred_data, trees, coefs, eta)\n",
    "result = pd.concat([test['Id'], pd.Series(pred_labels)], axis=1)\n",
    "result = result.rename(columns={0: 'mean_exam_points'})\n",
    "result.to_csv('IMarchenko_predictions.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
